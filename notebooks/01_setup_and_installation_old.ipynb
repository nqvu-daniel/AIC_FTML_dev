{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIC Video Retrieval System - Setup & Installation\n",
    "\n",
    "This notebook sets up the complete AIC video retrieval system from GitHub and installs all dependencies.\n",
    "It's designed to run independently on any cloud platform (Colab, Kaggle, etc.).\n",
    "\n",
    "## Features\n",
    "- üöÄ Self-contained setup from GitHub\n",
    "- üì¶ Automatic dependency installation\n",
    "- üîß Environment validation\n",
    "- üíæ GPU detection and setup\n",
    "- üóÇÔ∏è Directory structure creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're running in Colab/Kaggle or other cloud platform\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_KAGGLE = 'kaggle' in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "IN_CLOUD = IN_COLAB or IN_KAGGLE or 'COLAB_GPU' in os.environ\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  Google Colab: {IN_COLAB}\")\n",
    "print(f\"  Kaggle: {IN_KAGGLE}\")\n",
    "print(f\"  Cloud Platform: {IN_CLOUD}\")\n",
    "\n",
    "# Set working directory\n",
    "WORK_DIR = Path('/content') if IN_CLOUD else Path.cwd()\n",
    "print(f\"  Working directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "REPO_URL = \"https://github.com/danielqvu/AIC_FTML_dev.git\"  # Update this to your repo URL\n",
    "REPO_NAME = \"AIC_FTML_dev\"\n",
    "REPO_DIR = WORK_DIR / REPO_NAME\n",
    "\n",
    "# Clone or update repository\n",
    "if REPO_DIR.exists():\n",
    "    print(f\"Repository already exists at {REPO_DIR}\")\n",
    "    print(\"Updating repository...\")\n",
    "    os.chdir(REPO_DIR)\n",
    "    !git pull origin main\n",
    "else:\n",
    "    print(f\"Cloning repository to {REPO_DIR}\")\n",
    "    os.chdir(WORK_DIR)\n",
    "    !git clone {REPO_URL}\n",
    "    \n",
    "# Change to repo directory\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "if str(REPO_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "print(\"‚úÖ Repository setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: System Information & GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system information\n",
    "print(\"=== System Information ===\")\n",
    "!python --version\n",
    "!pip --version\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"\\n=== GPU Information ===\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not yet installed\")\n",
    "\n",
    "# Memory information\n",
    "print(\"\\n=== Memory Information ===\")\n",
    "!free -h 2>/dev/null || echo \"Memory info not available on this system\"\n",
    "\n",
    "# Disk space\n",
    "print(\"\\n=== Disk Space ===\")\n",
    "!df -h . | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "print(\"Installing system dependencies...\")\n",
    "if IN_COLAB:\n",
    "    !apt-get update -q\n",
    "    !apt-get install -y ffmpeg libsm6 libxext6 libfontconfig1 libxrender1\n",
    "\n",
    "print(\"\\n=== Installing Python Dependencies ===\")\n",
    "\n",
    "# Upgrade pip first\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Install requirements\n",
    "if Path(\"requirements.txt\").exists():\n",
    "    print(\"Installing from requirements.txt...\")\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    print(\"No requirements.txt found. Installing core dependencies...\")\n",
    "    # Core dependencies for the AIC system\n",
    "    core_packages = [\n",
    "        \"torch\",\n",
    "        \"torchvision\", \n",
    "        \"transformers\",\n",
    "        \"sentence-transformers\",\n",
    "        \"faiss-cpu\",  # or faiss-gpu if available\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"pillow\",\n",
    "        \"opencv-python\",\n",
    "        \"tqdm\",\n",
    "        \"scikit-learn\",\n",
    "        \"matplotlib\",\n",
    "        \"seaborn\",\n",
    "        \"ipywidgets\",\n",
    "        \"jupyterlab\"\n",
    "    ]\n",
    "    \n",
    "    for package in core_packages:\n",
    "        print(f\"Installing {package}...\")\n",
    "        !pip install {package}\n",
    "\n",
    "print(\"‚úÖ Dependencies installation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install GPU-Optimized FAISS (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to install GPU FAISS if CUDA is available\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA detected. Installing GPU-optimized FAISS...\")\n",
    "        !pip uninstall -y faiss-cpu faiss-gpu\n",
    "        !pip install faiss-gpu\n",
    "        print(\"‚úÖ GPU FAISS installed\")\n",
    "    else:\n",
    "        print(\"No CUDA available. Using CPU FAISS.\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not install GPU FAISS: {e}\")\n",
    "    print(\"Falling back to CPU FAISS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Validate Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test core imports\n",
    "print(\"=== Testing Core Imports ===\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import transformers\n",
    "    import sentence_transformers\n",
    "    import faiss\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    print(\"‚úÖ All core imports successful\")\n",
    "    \n",
    "    # Print versions\n",
    "    print(f\"\\nVersions:\")\n",
    "    print(f\"  PyTorch: {torch.__version__}\")\n",
    "    print(f\"  Transformers: {transformers.__version__}\")\n",
    "    print(f\"  Sentence Transformers: {sentence_transformers.__version__}\")\n",
    "    print(f\"  FAISS: {faiss.__version__}\")\n",
    "    print(f\"  OpenCV: {cv2.__version__}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "\n",
    "# Test project imports\n",
    "print(\"\\n=== Testing Project Imports ===\")\n",
    "try:\n",
    "    # Try to import project modules\n",
    "    import config\n",
    "    print(\"‚úÖ Config module imported\")\n",
    "    \n",
    "    # Test if we can import from src\n",
    "    sys.path.append(str(Path.cwd() / \"src\"))\n",
    "    from src.models.clip_encoder import CLIPEncoder\n",
    "    print(\"‚úÖ CLIP encoder imported\")\n",
    "    \n",
    "    from src.indexing.vector_index import VectorIndex\n",
    "    print(\"‚úÖ Vector index imported\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Project import warning: {e}\")\n",
    "    print(\"This may be normal if some modules are missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Setup Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "print(\"=== Setting up Directory Structure ===\")\n",
    "\n",
    "directories = [\n",
    "    \"data\",\n",
    "    \"data/dataset_metadata\", \n",
    "    \"artifacts\",\n",
    "    \"output\",\n",
    "    \"logs\",\n",
    "    \"temp\"\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    dir_path = Path(directory)\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created/verified: {directory}\")\n",
    "\n",
    "# Show current directory structure\n",
    "print(\"\\n=== Current Project Structure ===\")\n",
    "!find . -type d -name \".*\" -prune -o -type d -print | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Configuration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test configuration and create simple config if needed\n",
    "print(\"=== Configuration Test ===\")\n",
    "\n",
    "try:\n",
    "    import config\n",
    "    print(f\"‚úÖ Config loaded\")\n",
    "    print(f\"  Artifact dir: {config.ARTIFACT_DIR}\")\n",
    "    print(f\"  Model name: {getattr(config, 'MODEL_NAME', 'Not set')}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Config module not found or has issues\")\n",
    "    \n",
    "    # Create a basic config\n",
    "    config_content = \"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "# Directories\n",
    "ARTIFACT_DIR = Path(\"./artifacts\")\n",
    "DATA_DIR = Path(\"./data\")\n",
    "OUTPUT_DIR = Path(\"./output\")\n",
    "\n",
    "# Model settings\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Search settings\n",
    "DEFAULT_K = 100\n",
    "RERANK_TOP_K = 1000\n",
    "\"\"\"\n",
    "    \n",
    "    with open(\"config.py\", \"w\") as f:\n",
    "        f.write(config_content)\n",
    "    print(\"‚úÖ Created basic config.py\")\n",
    "\n",
    "print(\"\\nüéâ Setup complete! You can now proceed to the next notebooks.\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Use 02_data_processing.ipynb to download and process data\")\n",
    "print(\"2. Use 03_search_and_evaluation.ipynb to test search functionality\")\n",
    "print(\"3. Use 04_training_and_reranking.ipynb to improve search results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final health check\n",
    "print(\"=== Final Health Check ===\")\n",
    "\n",
    "# Check Python environment\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if key files exist\n",
    "key_files = [\n",
    "    \"config.py\",\n",
    "    \"src/models/clip_encoder.py\",\n",
    "    \"src/indexing/vector_index.py\",\n",
    "    \"smart_pipeline.py\",\n",
    "    \"search.py\"\n",
    "]\n",
    "\n",
    "print(\"\\nKey files check:\")\n",
    "for file_path in key_files:\n",
    "    exists = Path(file_path).exists()\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"  {status} {file_path}\")\n",
    "\n",
    "# Check GPU setup\n",
    "print(\"\\nGPU Status:\")\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.get_device_name(0)\n",
    "        memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"  ‚úÖ GPU available: {device} ({memory:.1f}GB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è No GPU available, using CPU\")\n",
    "except:\n",
    "    print(f\"  ‚ùå Could not check GPU status\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üöÄ SETUP COMPLETE! Ready for video retrieval tasks.\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}