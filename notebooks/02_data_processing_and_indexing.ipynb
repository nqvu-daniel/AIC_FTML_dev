{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIC Video Retrieval System - Data Processing & Indexing\n",
    "\n",
    "This notebook handles dataset download, video processing, frame extraction, and vector indexing.\n",
    "It can run independently on any cloud platform after running the setup notebook.\n",
    "\n",
    "## Features\n",
    "- üì• Download AIC dataset with progress tracking\n",
    "- üé• Intelligent video frame sampling\n",
    "- üñºÔ∏è CLIP-based image encoding\n",
    "- üîç FAISS vector index construction\n",
    "- üíæ Optimized storage and retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# Set up paths (assuming setup notebook was run)\n",
    "REPO_NAME = \"AIC_FTML_dev\"\n",
    "if Path(f\"/content/{REPO_NAME}\").exists():\n",
    "    REPO_DIR = Path(f\"/content/{REPO_NAME}\")\n",
    "else:\n",
    "    REPO_DIR = Path.cwd()\n",
    "    while REPO_DIR.name != REPO_NAME and REPO_DIR.parent != REPO_DIR:\n",
    "        REPO_DIR = REPO_DIR.parent\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, str(REPO_DIR))\n",
    "sys.path.insert(0, str(REPO_DIR / \"src\"))\n",
    "\n",
    "print(f\"Working from: {REPO_DIR}\")\n",
    "\n",
    "# Import project modules\n",
    "import config\n",
    "from src.models.clip_encoder import CLIPEncoder\n",
    "from src.indexing.vector_index import VectorIndex\n",
    "from src.sampling.frames_auto import VideoFrameSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DOWNLOAD_SUBSET = True  # Set to False to download full dataset\n",
    "SUBSET_SIZE = 50  # Number of videos for subset\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATASET_DIR = DATA_DIR / \"aic2025\"\n",
    "METADATA_DIR = DATA_DIR / \"dataset_metadata\"\n",
    "\n",
    "# Create directories\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "DATASET_DIR.mkdir(exist_ok=True)\n",
    "METADATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Dataset configuration:\")\n",
    "print(f\"  Download subset: {DOWNLOAD_SUBSET}\")\n",
    "print(f\"  Subset size: {SUBSET_SIZE if DOWNLOAD_SUBSET else 'Full dataset'}\")\n",
    "print(f\"  Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"  Metadata directory: {METADATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset metadata and links\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "def download_with_progress(url, filename):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(filename, 'wb') as f, tqdm(\n",
    "        desc=filename.name,\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "    return filename\n",
    "\n",
    "# Check if we have the dataset links CSV\n",
    "csv_file = Path(\"AIC_2025_dataset_download_link.csv\")\n",
    "if not csv_file.exists():\n",
    "    print(\"‚ùå Dataset links CSV not found\")\n",
    "    print(\"Please ensure AIC_2025_dataset_download_link.csv is available\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset links CSV found\")\n",
    "    \n",
    "    # Read dataset links\n",
    "    df_links = pd.read_csv(csv_file)\n",
    "    print(f\"Found {len(df_links)} videos in dataset\")\n",
    "    \n",
    "    if DOWNLOAD_SUBSET:\n",
    "        df_links = df_links.head(SUBSET_SIZE)\n",
    "        print(f\"Processing subset of {len(df_links)} videos\")\n",
    "    \n",
    "    display(df_links.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset using the built-in downloader\n",
    "print(\"=== Starting Dataset Download ===\")\n",
    "\n",
    "if csv_file.exists():\n",
    "    # Run the dataset downloader\n",
    "    download_script = Path(\"scripts/dataset_downloader.py\")\n",
    "    if download_script.exists():\n",
    "        cmd = f\"python {download_script} --output_dir {DATASET_DIR}\"\n",
    "        if DOWNLOAD_SUBSET:\n",
    "            cmd += f\" --max_videos {SUBSET_SIZE}\"\n",
    "        \n",
    "        print(f\"Running: {cmd}\")\n",
    "        !{cmd}\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dataset downloader script not found, using manual download...\")\n",
    "        \n",
    "        # Manual download fallback\n",
    "        for idx, row in tqdm(df_links.iterrows(), total=len(df_links), desc=\"Downloading videos\"):\n",
    "            video_id = row['video_id']\n",
    "            video_url = row['video_url']\n",
    "            \n",
    "            video_file = DATASET_DIR / f\"{video_id}.mp4\"\n",
    "            if not video_file.exists():\n",
    "                try:\n",
    "                    download_with_progress(video_url, video_file)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to download {video_id}: {e}\")\n",
    "                    continue\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping download - CSV file not found\")\n",
    "    print(\"Please place AIC_2025_dataset_download_link.csv in the repo root\")\n",
    "\n",
    "# Check what we have\n",
    "video_files = list(DATASET_DIR.glob(\"*.mp4\"))\n",
    "print(f\"\\n‚úÖ Downloaded {len(video_files)} video files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Frame Extraction and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize frame sampler\n",
    "print(\"=== Frame Extraction Setup ===\")\n",
    "\n",
    "# Configuration\n",
    "FRAMES_DIR = Path(\"./keyframes\")\n",
    "FRAMES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Sampling parameters\n",
    "SAMPLING_MODE = \"intelligent\"  # \"uniform\", \"intelligent\", or \"adaptive\"\n",
    "FRAMES_PER_VIDEO = 10  # Number of frames to extract per video\n",
    "MIN_INTERVAL = 2.0  # Minimum seconds between frames\n",
    "\n",
    "print(f\"Frame extraction configuration:\")\n",
    "print(f\"  Output directory: {FRAMES_DIR}\")\n",
    "print(f\"  Sampling mode: {SAMPLING_MODE}\")\n",
    "print(f\"  Frames per video: {FRAMES_PER_VIDEO}\")\n",
    "print(f\"  Min interval: {MIN_INTERVAL}s\")\n",
    "\n",
    "# Initialize sampler\n",
    "try:\n",
    "    sampler = VideoFrameSampler(\n",
    "        output_dir=FRAMES_DIR,\n",
    "        sampling_mode=SAMPLING_MODE,\n",
    "        frames_per_video=FRAMES_PER_VIDEO,\n",
    "        min_interval=MIN_INTERVAL\n",
    "    )\n",
    "    print(\"‚úÖ Frame sampler initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not initialize frame sampler: {e}\")\n",
    "    print(\"Using fallback frame extraction...\")\n",
    "    sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames from videos\n",
    "print(\"=== Frame Extraction ===\")\n",
    "\n",
    "video_files = list(DATASET_DIR.glob(\"*.mp4\"))\n",
    "if not video_files:\n",
    "    print(\"‚ùå No video files found. Please run the download step first.\")\n",
    "else:\n",
    "    print(f\"Processing {len(video_files)} videos...\")\n",
    "    \n",
    "    frame_metadata = []  # Track frame information\n",
    "    \n",
    "    for video_file in tqdm(video_files, desc=\"Extracting frames\"):\n",
    "        video_id = video_file.stem\n",
    "        \n",
    "        try:\n",
    "            if sampler:\n",
    "                # Use intelligent sampler\n",
    "                frames_info = sampler.sample_video(video_file, video_id)\n",
    "            else:\n",
    "                # Fallback: extract frames uniformly\n",
    "                import cv2\n",
    "                \n",
    "                cap = cv2.VideoCapture(str(video_file))\n",
    "                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                duration = total_frames / fps if fps > 0 else 0\n",
    "                \n",
    "                frames_info = []\n",
    "                if total_frames > 0:\n",
    "                    step = max(1, total_frames // FRAMES_PER_VIDEO)\n",
    "                    \n",
    "                    for i in range(0, total_frames, step):\n",
    "                        if len(frames_info) >= FRAMES_PER_VIDEO:\n",
    "                            break\n",
    "                            \n",
    "                        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "                        ret, frame = cap.read()\n",
    "                        if ret:\n",
    "                            # Save frame\n",
    "                            frame_filename = FRAMES_DIR / f\"{video_id}_frame_{i:06d}.jpg\"\n",
    "                            cv2.imwrite(str(frame_filename), frame)\n",
    "                            \n",
    "                            frames_info.append({\n",
    "                                'video_id': video_id,\n",
    "                                'frame_idx': i,\n",
    "                                'timestamp': i / fps if fps > 0 else 0,\n",
    "                                'frame_path': str(frame_filename)\n",
    "                            })\n",
    "                \n",
    "                cap.release()\n",
    "            \n",
    "            frame_metadata.extend(frames_info)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ Extracted {len(frame_metadata)} frames total\")\n",
    "    \n",
    "    # Save frame metadata\n",
    "    if frame_metadata:\n",
    "        metadata_df = pd.DataFrame(frame_metadata)\n",
    "        metadata_file = METADATA_DIR / \"frame_metadata.parquet\"\n",
    "        metadata_df.to_parquet(metadata_file, index=False)\n",
    "        print(f\"‚úÖ Saved frame metadata to {metadata_file}\")\n",
    "        \n",
    "        # Show statistics\n",
    "        print(f\"\\nFrame extraction statistics:\")\n",
    "        print(f\"  Total frames: {len(metadata_df)}\")\n",
    "        print(f\"  Videos processed: {metadata_df['video_id'].nunique()}\")\n",
    "        print(f\"  Avg frames per video: {len(metadata_df) / metadata_df['video_id'].nunique():.1f}\")\n",
    "        \n",
    "        display(metadata_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: CLIP Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIP encoder\n",
    "print(\"=== CLIP Encoder Setup ===\")\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load CLIP encoder\n",
    "try:\n",
    "    encoder = CLIPEncoder(\n",
    "        model_name=config.MODEL_NAME,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"‚úÖ CLIP encoder loaded: {config.MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CLIP encoder: {e}\")\n",
    "    # Fallback to direct CLIP loading\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    encoder = SentenceTransformer('clip-ViT-B-32')\n",
    "    print(\"‚úÖ Fallback CLIP encoder loaded\")\n",
    "\n",
    "print(f\"Encoding configuration:\")\n",
    "print(f\"  Batch size: {getattr(config, 'BATCH_SIZE', 32)}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all extracted frames\n",
    "print(\"=== Frame Encoding ===\")\n",
    "\n",
    "# Load frame metadata\n",
    "metadata_file = METADATA_DIR / \"frame_metadata.parquet\"\n",
    "if not metadata_file.exists():\n",
    "    print(\"‚ùå Frame metadata not found. Please run frame extraction first.\")\n",
    "else:\n",
    "    metadata_df = pd.read_parquet(metadata_file)\n",
    "    print(f\"Loading {len(metadata_df)} frames for encoding...\")\n",
    "    \n",
    "    # Batch encoding for efficiency\n",
    "    BATCH_SIZE = getattr(config, 'BATCH_SIZE', 32)\n",
    "    all_embeddings = []\n",
    "    valid_frames = []  # Track which frames were successfully encoded\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(metadata_df), BATCH_SIZE), desc=\"Encoding frames\"):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, len(metadata_df))\n",
    "        batch_df = metadata_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Load batch of images\n",
    "        batch_images = []\n",
    "        batch_valid_indices = []\n",
    "        \n",
    "        for idx, row in batch_df.iterrows():\n",
    "            frame_path = Path(row['frame_path'])\n",
    "            if frame_path.exists():\n",
    "                try:\n",
    "                    from PIL import Image\n",
    "                    img = Image.open(frame_path).convert('RGB')\n",
    "                    batch_images.append(img)\n",
    "                    batch_valid_indices.append(idx)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {frame_path}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if batch_images:\n",
    "            try:\n",
    "                # Encode batch\n",
    "                if hasattr(encoder, 'encode_images'):\n",
    "                    batch_embeddings = encoder.encode_images(batch_images)\n",
    "                else:\n",
    "                    # Fallback for sentence-transformers\n",
    "                    batch_embeddings = encoder.encode(batch_images)\n",
    "                \n",
    "                all_embeddings.extend(batch_embeddings)\n",
    "                valid_frames.extend(batch_valid_indices)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error encoding batch: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if all_embeddings:\n",
    "        # Convert to numpy array\n",
    "        embeddings_array = np.array(all_embeddings)\n",
    "        print(f\"\\n‚úÖ Encoded {len(embeddings_array)} frames\")\n",
    "        print(f\"Embedding shape: {embeddings_array.shape}\")\n",
    "        \n",
    "        # Filter metadata to only valid frames\n",
    "        valid_metadata_df = metadata_df.iloc[valid_frames].reset_index(drop=True)\n",
    "        \n",
    "        # Save embeddings and metadata\n",
    "        embeddings_file = METADATA_DIR / \"frame_embeddings.npy\"\n",
    "        np.save(embeddings_file, embeddings_array)\n",
    "        \n",
    "        valid_metadata_file = METADATA_DIR / \"valid_frame_metadata.parquet\"\n",
    "        valid_metadata_df.to_parquet(valid_metadata_file, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Saved embeddings to {embeddings_file}\")\n",
    "        print(f\"‚úÖ Saved valid metadata to {valid_metadata_file}\")\n",
    "    else:\n",
    "        print(\"‚ùå No embeddings generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index\n",
    "print(\"=== Vector Index Construction ===\")\n",
    "\n",
    "# Load embeddings\n",
    "embeddings_file = METADATA_DIR / \"frame_embeddings.npy\"\n",
    "valid_metadata_file = METADATA_DIR / \"valid_frame_metadata.parquet\"\n",
    "\n",
    "if not embeddings_file.exists():\n",
    "    print(\"‚ùå Embeddings not found. Please run encoding first.\")\n",
    "else:\n",
    "    embeddings = np.load(embeddings_file)\n",
    "    metadata_df = pd.read_parquet(valid_metadata_file)\n",
    "    \n",
    "    print(f\"Building index for {len(embeddings)} embeddings...\")\n",
    "    print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "    \n",
    "    # Normalize embeddings for cosine similarity\n",
    "    from sklearn.preprocessing import normalize\n",
    "    embeddings_normalized = normalize(embeddings, norm='l2')\n",
    "    \n",
    "    # Build FAISS index\n",
    "    import faiss\n",
    "    \n",
    "    # Choose index type based on dataset size\n",
    "    if len(embeddings) < 10000:\n",
    "        # Use flat index for small datasets\n",
    "        index = faiss.IndexFlatIP(embeddings.shape[1])  # Inner product for normalized vectors\n",
    "        print(\"Using IndexFlatIP for small dataset\")\n",
    "    else:\n",
    "        # Use HNSW for larger datasets\n",
    "        index = faiss.IndexHNSWFlat(embeddings.shape[1], 32)\n",
    "        index.hnsw.efConstruction = 200\n",
    "        print(\"Using IndexHNSWFlat for larger dataset\")\n",
    "    \n",
    "    # Add embeddings to index\n",
    "    index.add(embeddings_normalized.astype(np.float32))\n",
    "    \n",
    "    print(f\"‚úÖ Index built with {index.ntotal} vectors\")\n",
    "    \n",
    "    # Save index and metadata to artifacts directory\n",
    "    ARTIFACT_DIR = Path(config.ARTIFACT_DIR)\n",
    "    ARTIFACT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    index_file = ARTIFACT_DIR / \"vector_index.faiss\"\n",
    "    metadata_file = ARTIFACT_DIR / \"index_metadata.parquet\"\n",
    "    \n",
    "    faiss.write_index(index, str(index_file))\n",
    "    metadata_df.to_parquet(metadata_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Saved index to {index_file}\")\n",
    "    print(f\"‚úÖ Saved metadata to {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Index Validation & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the built index\n",
    "print(\"=== Index Validation ===\")\n",
    "\n",
    "ARTIFACT_DIR = Path(config.ARTIFACT_DIR)\n",
    "index_file = ARTIFACT_DIR / \"vector_index.faiss\"\n",
    "metadata_file = ARTIFACT_DIR / \"index_metadata.parquet\"\n",
    "\n",
    "if index_file.exists() and metadata_file.exists():\n",
    "    # Load index and metadata\n",
    "    index = faiss.read_index(str(index_file))\n",
    "    metadata_df = pd.read_parquet(metadata_file)\n",
    "    \n",
    "    print(f\"Index validation:\")\n",
    "    print(f\"  Index size: {index.ntotal} vectors\")\n",
    "    print(f\"  Metadata size: {len(metadata_df)} entries\")\n",
    "    print(f\"  Dimension: {index.d}\")\n",
    "    print(f\"  Index type: {type(index).__name__}\")\n",
    "    \n",
    "    # Test search functionality\n",
    "    print(\"\\nTesting search functionality...\")\n",
    "    query_vector = np.random.randn(1, index.d).astype(np.float32)\n",
    "    query_vector = query_vector / np.linalg.norm(query_vector)  # Normalize\n",
    "    \n",
    "    k = min(5, index.ntotal)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    \n",
    "    print(f\"‚úÖ Search test successful - returned {len(indices[0])} results\")\n",
    "    print(f\"Sample distances: {distances[0][:3]}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"\\n=== Dataset Statistics ===\")\n",
    "    print(f\"Total frames indexed: {len(metadata_df)}\")\n",
    "    print(f\"Unique videos: {metadata_df['video_id'].nunique()}\")\n",
    "    print(f\"Avg frames per video: {len(metadata_df) / metadata_df['video_id'].nunique():.1f}\")\n",
    "    \n",
    "    # Video distribution\n",
    "    video_counts = metadata_df['video_id'].value_counts()\n",
    "    print(f\"\\nFrames per video distribution:\")\n",
    "    print(f\"  Min: {video_counts.min()}\")\n",
    "    print(f\"  Max: {video_counts.max()}\")\n",
    "    print(f\"  Mean: {video_counts.mean():.1f}\")\n",
    "    print(f\"  Median: {video_counts.median():.1f}\")\n",
    "    \n",
    "    # Show sample entries\n",
    "    print(\"\\nSample index entries:\")\n",
    "    display(metadata_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Index files not found. Please run the indexing step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Training Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data for reranking\n",
    "print(\"=== Training Data Generation ===\")\n",
    "\n",
    "CREATE_TRAINING_DATA = True  # Set to True to generate training data\n",
    "\n",
    "if CREATE_TRAINING_DATA:\n",
    "    try:\n",
    "        from utils.create_training_data import create_training_data_from_metadata\n",
    "        \n",
    "        success = create_training_data_from_metadata(\n",
    "            dataset_root=str(DATASET_DIR.parent),\n",
    "            output_file=\"data/train.jsonl\",\n",
    "            num_examples=50\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(\"‚úÖ Training data generated successfully\")\n",
    "            \n",
    "            # Show sample training data\n",
    "            training_file = Path(\"data/train.jsonl\")\n",
    "            if training_file.exists():\n",
    "                with open(training_file, 'r') as f:\n",
    "                    sample_lines = [next(f) for _ in range(3)]\n",
    "                \n",
    "                print(\"\\nSample training examples:\")\n",
    "                for i, line in enumerate(sample_lines, 1):\n",
    "                    data = json.loads(line)\n",
    "                    print(f\"{i}. Query: '{data['query']}'\")\n",
    "                    print(f\"   Positives: {len(data['positives'])} frames\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Training data generation failed\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è Training data utility not available\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training data generation skipped\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ DATA PROCESSING COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Use 03_search_and_evaluation.ipynb to test search\")\n",
    "print(\"2. Use 04_training_and_reranking.ipynb to improve results\")\n",
    "print(\"3. Use 05_end_to_end_pipeline.ipynb for complete workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Artifacts\n",
    "\n",
    "This notebook has processed your video dataset and created the following artifacts:\n",
    "\n",
    "### Generated Files:\n",
    "- `artifacts/vector_index.faiss` - FAISS vector index for similarity search\n",
    "- `artifacts/index_metadata.parquet` - Frame metadata with video_id, frame_idx, timestamps\n",
    "- `data/dataset_metadata/frame_embeddings.npy` - CLIP embeddings for all frames\n",
    "- `data/train.jsonl` - Training data for reranker (if generated)\n",
    "- `keyframes/` - Extracted video frames\n",
    "\n",
    "### Index Statistics:\n",
    "The index is now ready for similarity search using CLIP embeddings. You can search using text queries or image queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}