{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIC Video Retrieval System - Search & Evaluation\n",
    "\n",
    "This notebook provides an interactive interface for searching the video index and evaluating results.\n",
    "It works with the index built in the previous notebook and provides various search modes.\n",
    "\n",
    "## Features\n",
    "- üîç Text-based similarity search\n",
    "- üñºÔ∏è Image-based similarity search  \n",
    "- üîÄ Hybrid search combining multiple modes\n",
    "- üìä Interactive result visualization\n",
    "- üìà Performance evaluation metrics\n",
    "- üíæ Export search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Image as IPImage, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import time\n",
    "\n",
    "# Set up paths (assuming setup notebook was run)\n",
    "REPO_NAME = \"AIC_FTML_dev\"\n",
    "if Path(f\"/content/{REPO_NAME}\").exists():\n",
    "    REPO_DIR = Path(f\"/content/{REPO_NAME}\")\n",
    "else:\n",
    "    REPO_DIR = Path.cwd()\n",
    "    while REPO_DIR.name != REPO_NAME and REPO_DIR.parent != REPO_DIR:\n",
    "        REPO_DIR = REPO_DIR.parent\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, str(REPO_DIR))\n",
    "sys.path.insert(0, str(REPO_DIR / \"src\"))\n",
    "\n",
    "print(f\"Working from: {REPO_DIR}\")\n",
    "\n",
    "# Import project modules\n",
    "import config\n",
    "from src.models.clip_encoder import CLIPEncoder\n",
    "from src.indexing.vector_index import VectorIndex\n",
    "from src.pipeline.query_pipeline import QueryProcessingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Index and Initialize Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize search system\n",
    "print(\"=== Search System Initialization ===\")\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if index exists\n",
    "ARTIFACT_DIR = Path(config.ARTIFACT_DIR)\n",
    "index_file = ARTIFACT_DIR / \"vector_index.faiss\"\n",
    "metadata_file = ARTIFACT_DIR / \"index_metadata.parquet\"\n",
    "\n",
    "if not index_file.exists() or not metadata_file.exists():\n",
    "    print(\"‚ùå Index not found. Please run the data processing notebook first.\")\n",
    "    print(f\"Looking for:\")\n",
    "    print(f\"  Index: {index_file}\")\n",
    "    print(f\"  Metadata: {metadata_file}\")\n",
    "else:\n",
    "    print(\"‚úÖ Index files found\")\n",
    "    \n",
    "    # Initialize query pipeline\n",
    "    try:\n",
    "        query_pipeline = QueryProcessingPipeline(\n",
    "            artifact_dir=ARTIFACT_DIR,\n",
    "            model_name=config.MODEL_NAME,\n",
    "            device=device,\n",
    "            enable_reranking=False  # Start without reranking\n",
    "        )\n",
    "        print(\"‚úÖ Query pipeline initialized\")\n",
    "        \n",
    "        # Load metadata for display\n",
    "        metadata_df = pd.read_parquet(metadata_file)\n",
    "        print(f\"‚úÖ Loaded metadata for {len(metadata_df)} frames\")\n",
    "        print(f\"   Videos: {metadata_df['video_id'].nunique()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing pipeline: {e}\")\n",
    "        print(\"Falling back to basic search...\")\n",
    "        query_pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic Search Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple search function\n",
    "def perform_search(query, search_mode=\"hybrid\", k=20, expand_query=False):\n",
    "    \"\"\"Perform search and return results\"\"\"\n",
    "    if query_pipeline is None:\n",
    "        return [], \"Query pipeline not available\"\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = query_pipeline.search(\n",
    "            query=query,\n",
    "            search_mode=search_mode,\n",
    "            k=k,\n",
    "            expand_query=expand_query\n",
    "        )\n",
    "        \n",
    "        search_time = time.time() - start_time\n",
    "        return results, f\"Found {len(results)} results in {search_time:.3f}s\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return [], f\"Search error: {e}\"\n",
    "\n",
    "def display_results(results, query, max_display=10):\n",
    "    \"\"\"Display search results with images if available\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüîç Search Results for: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_data = []\n",
    "    for i, result in enumerate(results[:max_display]):\n",
    "        results_data.append({\n",
    "            'Rank': i + 1,\n",
    "            'Video ID': result.video_id,\n",
    "            'Frame': result.frame_idx,\n",
    "            'Score': f\"{result.score:.4f}\",\n",
    "            'Search Type': result.metadata.get('search_type', 'unknown')\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    display(results_df)\n",
    "    \n",
    "    # Try to display images if frame paths exist\n",
    "    keyframes_dir = Path(\"./keyframes\")\n",
    "    if keyframes_dir.exists():\n",
    "        print(\"\\nüì∏ Sample Result Images:\")\n",
    "        images_shown = 0\n",
    "        \n",
    "        for result in results[:5]:  # Show first 5 images\n",
    "            # Try to find the frame image\n",
    "            possible_paths = [\n",
    "                keyframes_dir / f\"{result.video_id}_frame_{result.frame_idx:06d}.jpg\",\n",
    "                keyframes_dir / f\"{result.video_id}\" / f\"frame_{result.frame_idx:06d}.jpg\",\n",
    "                keyframes_dir / f\"{result.video_id}_frame_{result.frame_idx}.jpg\"\n",
    "            ]\n",
    "            \n",
    "            for img_path in possible_paths:\n",
    "                if img_path.exists():\n",
    "                    try:\n",
    "                        display(HTML(f\"<h4>Rank {images_shown + 1}: {result.video_id} - Frame {result.frame_idx} (Score: {result.score:.3f})</h4>\"))\n",
    "                        display(IPImage(filename=str(img_path), width=300))\n",
    "                        images_shown += 1\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        if images_shown == 0:\n",
    "            print(\"‚ö†Ô∏è No frame images found for display\")\n",
    "\n",
    "# Test search function\n",
    "if query_pipeline:\n",
    "    print(\"\\nüß™ Testing search functionality...\")\n",
    "    test_results, status = perform_search(\"news anchor\", k=5)\n",
    "    print(status)\n",
    "    if test_results:\n",
    "        print(f\"‚úÖ Search working - sample result: {test_results[0].video_id}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Search functionality not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Interactive Search Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive search widget\n",
    "if query_pipeline:\n",
    "    print(\"üéõÔ∏è Interactive Search Interface\")\n",
    "    \n",
    "    # Search parameters\n",
    "    query_widget = widgets.Text(\n",
    "        value='news anchor speaking',\n",
    "        placeholder='Enter your search query...',\n",
    "        description='Query:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    search_mode_widget = widgets.Dropdown(\n",
    "        options=[('Hybrid', 'hybrid'), ('Vector Only', 'vector'), ('Text Only', 'text')],\n",
    "        value='hybrid',\n",
    "        description='Search Mode:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    k_widget = widgets.IntSlider(\n",
    "        value=20,\n",
    "        min=5,\n",
    "        max=100,\n",
    "        step=5,\n",
    "        description='Results:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    expand_query_widget = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Expand Query',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    max_display_widget = widgets.IntSlider(\n",
    "        value=10,\n",
    "        min=5,\n",
    "        max=50,\n",
    "        step=5,\n",
    "        description='Max Display:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Interactive search function\n",
    "    def interactive_search(query, search_mode, k, expand_query, max_display):\n",
    "        if not query.strip():\n",
    "            print(\"Please enter a search query\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîç Searching for: '{query}'\")\n",
    "        print(f\"Mode: {search_mode}, Results: {k}, Expand: {expand_query}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        results, status = perform_search(query, search_mode, k, expand_query)\n",
    "        print(status)\n",
    "        \n",
    "        if results:\n",
    "            display_results(results, query, max_display)\n",
    "    \n",
    "    # Create interactive widget\n",
    "    search_widget = interactive(\n",
    "        interactive_search,\n",
    "        query=query_widget,\n",
    "        search_mode=search_mode_widget,\n",
    "        k=k_widget,\n",
    "        expand_query=expand_query_widget,\n",
    "        max_display=max_display_widget\n",
    "    )\n",
    "    \n",
    "    display(search_widget)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Interactive search not available - pipeline not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Predefined Query Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined example queries\n",
    "example_queries = {\n",
    "    \"News & Media\": [\n",
    "        \"news anchor speaking\",\n",
    "        \"television broadcast\",\n",
    "        \"reporter on camera\",\n",
    "        \"live news show\",\n",
    "        \"studio presentation\"\n",
    "    ],\n",
    "    \"Vietnamese Content\": [\n",
    "        \"tin t·ª©c m·ªõi nh·∫•t\",\n",
    "        \"b·∫£n tin h√¥m nay\",\n",
    "        \"th·ªùi s·ª± vi·ªát nam\",\n",
    "        \"HTV tin t·ª©c\",\n",
    "        \"b√°o c√°o th√¥ng tin\"\n",
    "    ],\n",
    "    \"General Content\": [\n",
    "        \"person presenting\",\n",
    "        \"people talking\",\n",
    "        \"professional broadcast\",\n",
    "        \"communication show\",\n",
    "        \"information program\"\n",
    "    ],\n",
    "    \"Visual Elements\": [\n",
    "        \"person wearing glasses\",\n",
    "        \"formal attire\",\n",
    "        \"microphone visible\",\n",
    "        \"indoor studio setting\",\n",
    "        \"text overlay on screen\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def run_example_queries():\n",
    "    \"\"\"Run example queries and show results\"\"\"\n",
    "    if not query_pipeline:\n",
    "        print(\"‚ùå Query pipeline not available\")\n",
    "        return\n",
    "    \n",
    "    print(\"üéØ Running Example Queries\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for category, queries in example_queries.items():\n",
    "        print(f\"\\nüìÇ {category}:\")\n",
    "        \n",
    "        for query in queries[:2]:  # Run first 2 queries per category\n",
    "            print(f\"\\nüîç '{query}'\")\n",
    "            results, status = perform_search(query, k=5)\n",
    "            print(f\"   {status}\")\n",
    "            \n",
    "            if results:\n",
    "                # Show top result\n",
    "                top_result = results[0]\n",
    "                print(f\"   Top result: {top_result.video_id} frame {top_result.frame_idx} (score: {top_result.score:.3f})\")\n",
    "                \n",
    "                # Store for analysis\n",
    "                all_results.append({\n",
    "                    'category': category,\n",
    "                    'query': query,\n",
    "                    'num_results': len(results),\n",
    "                    'top_score': top_result.score,\n",
    "                    'top_video': top_result.video_id\n",
    "                })\n",
    "            else:\n",
    "                print(\"   No results found\")\n",
    "                all_results.append({\n",
    "                    'category': category,\n",
    "                    'query': query,\n",
    "                    'num_results': 0,\n",
    "                    'top_score': 0.0,\n",
    "                    'top_video': None\n",
    "                })\n",
    "    \n",
    "    # Create summary\n",
    "    if all_results:\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        print(\"\\nüìä Example Query Results Summary:\")\n",
    "        display(results_df)\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\nStatistics:\")\n",
    "        print(f\"  Average results per query: {results_df['num_results'].mean():.1f}\")\n",
    "        print(f\"  Average top score: {results_df['top_score'].mean():.3f}\")\n",
    "        print(f\"  Queries with results: {(results_df['num_results'] > 0).sum()}/{len(results_df)}\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Run examples button\n",
    "if query_pipeline:\n",
    "    run_examples_button = widgets.Button(\n",
    "        description=\"Run Example Queries\",\n",
    "        button_style='info',\n",
    "        tooltip='Run predefined example queries'\n",
    "    )\n",
    "    \n",
    "    def on_run_examples_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            run_example_queries()\n",
    "    \n",
    "    run_examples_button.on_click(on_run_examples_clicked)\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    display(run_examples_button)\n",
    "    display(output)\nelse:\n",
    "    print(\"üìã Example queries available but pipeline not initialized\")\n",
    "    for category, queries in example_queries.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for query in queries:\n",
    "            print(f\"  - {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Search Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "def benchmark_search_performance():\n",
    "    \"\"\"Benchmark search performance across different modes\"\"\"\n",
    "    if not query_pipeline:\n",
    "        print(\"‚ùå Query pipeline not available for benchmarking\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚ö° Search Performance Benchmark\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"news anchor\",\n",
    "        \"person speaking\", \n",
    "        \"television broadcast\",\n",
    "        \"tin t·ª©c\",\n",
    "        \"studio presentation\"\n",
    "    ]\n",
    "    \n",
    "    search_modes = ['vector', 'hybrid']\n",
    "    k_values = [10, 50, 100]\n",
    "    \n",
    "    benchmark_results = []\n",
    "    \n",
    "    for mode in search_modes:\n",
    "        for k in k_values:\n",
    "            print(f\"\\nTesting {mode} search with k={k}\")\n",
    "            \n",
    "            times = []\n",
    "            result_counts = []\n",
    "            \n",
    "            for query in test_queries:\n",
    "                start_time = time.time()\n",
    "                results, _ = perform_search(query, search_mode=mode, k=k)\n",
    "                search_time = time.time() - start_time\n",
    "                \n",
    "                times.append(search_time)\n",
    "                result_counts.append(len(results))\n",
    "            \n",
    "            avg_time = np.mean(times)\n",
    "            avg_results = np.mean(result_counts)\n",
    "            \n",
    "            benchmark_results.append({\n",
    "                'search_mode': mode,\n",
    "                'k': k,\n",
    "                'avg_time_ms': avg_time * 1000,\n",
    "                'avg_results': avg_results,\n",
    "                'queries_per_second': len(test_queries) / sum(times)\n",
    "            })\n",
    "            \n",
    "            print(f\"  Average time: {avg_time*1000:.1f}ms\")\n",
    "            print(f\"  Average results: {avg_results:.1f}\")\n",
    "            print(f\"  QPS: {len(test_queries) / sum(times):.1f}\")\n",
    "    \n",
    "    # Create benchmark summary\n",
    "    benchmark_df = pd.DataFrame(benchmark_results)\n",
    "    \n",
    "    print(\"\\nüìä Performance Summary:\")\n",
    "    display(benchmark_df)\n",
    "    \n",
    "    # Visualize performance\n",
    "    if len(benchmark_df) > 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Response time by mode and k\n",
    "        sns.barplot(data=benchmark_df, x='k', y='avg_time_ms', hue='search_mode', ax=ax1)\n",
    "        ax1.set_title('Average Response Time by Search Mode')\n",
    "        ax1.set_ylabel('Response Time (ms)')\n",
    "        \n",
    "        # Queries per second\n",
    "        sns.barplot(data=benchmark_df, x='k', y='queries_per_second', hue='search_mode', ax=ax2)\n",
    "        ax2.set_title('Queries Per Second by Search Mode')\n",
    "        ax2.set_ylabel('QPS')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return benchmark_df\n",
    "\n",
    "# Run benchmark button\n",
    "if query_pipeline:\n",
    "    benchmark_button = widgets.Button(\n",
    "        description=\"Run Performance Benchmark\",\n",
    "        button_style='warning',\n",
    "        tooltip='Benchmark search performance'\n",
    "    )\n",
    "    \n",
    "    def on_benchmark_clicked(b):\n",
    "        with benchmark_output:\n",
    "            clear_output()\n",
    "            benchmark_search_performance()\n",
    "    \n",
    "    benchmark_button.on_click(on_benchmark_clicked)\n",
    "    benchmark_output = widgets.Output()\n",
    "    \n",
    "    display(benchmark_button)\n",
    "    display(benchmark_output)\nelse:\n",
    "    print(\"‚ö†Ô∏è Performance benchmark not available - pipeline not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export functionality\n",
    "def export_search_results(query, results, output_format=\"csv\"):\n",
    "    \"\"\"Export search results to file\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to export\")\n",
    "        return None\n",
    "    \n",
    "    # Create results dataframe\n",
    "    export_data = []\n",
    "    for i, result in enumerate(results):\n",
    "        export_data.append({\n",
    "            'rank': i + 1,\n",
    "            'video_id': result.video_id,\n",
    "            'frame_idx': result.frame_idx,\n",
    "            'score': result.score,\n",
    "            'search_type': result.metadata.get('search_type', 'unknown'),\n",
    "            'query': query,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        })\n",
    "    \n",
    "    export_df = pd.DataFrame(export_data)\n",
    "    \n",
    "    # Generate filename\n",
    "    safe_query = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '' for c in query)\n",
    "    safe_query = safe_query.replace(' ', '_')[:30]\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    output_dir = Path(\"./output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if output_format.lower() == \"csv\":\n",
    "        filename = output_dir / f\"search_results_{safe_query}_{timestamp}.csv\"\n",
    "        export_df.to_csv(filename, index=False)\n",
    "    elif output_format.lower() == \"json\":\n",
    "        filename = output_dir / f\"search_results_{safe_query}_{timestamp}.json\"\n",
    "        export_df.to_json(filename, orient='records', indent=2)\n",
    "    else:\n",
    "        filename = output_dir / f\"search_results_{safe_query}_{timestamp}.parquet\"\n",
    "        export_df.to_parquet(filename, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Exported {len(results)} results to {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Export widget\n",
    "if query_pipeline:\n",
    "    print(\"üíæ Export Search Results\")\n",
    "    \n",
    "    export_query_widget = widgets.Text(\n",
    "        value='news anchor',\n",
    "        placeholder='Query to search and export...',\n",
    "        description='Query:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    export_format_widget = widgets.Dropdown(\n",
    "        options=['csv', 'json', 'parquet'],\n",
    "        value='csv',\n",
    "        description='Format:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    export_k_widget = widgets.IntSlider(\n",
    "        value=100,\n",
    "        min=10,\n",
    "        max=500,\n",
    "        step=10,\n",
    "        description='Results:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def do_export(query, format_type, k):\n",
    "        if not query.strip():\n",
    "            print(\"Please enter a query\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîç Searching for '{query}' (k={k})...\")\n",
    "        results, status = perform_search(query, k=k)\n",
    "        print(status)\n",
    "        \n",
    "        if results:\n",
    "            export_search_results(query, results, format_type)\n",
    "        else:\n",
    "            print(\"‚ùå No results to export\")\n",
    "    \n",
    "    export_widget = interactive(\n",
    "        do_export,\n",
    "        query=export_query_widget,\n",
    "        format_type=export_format_widget,\n",
    "        k=export_k_widget\n",
    "    )\n",
    "    \n",
    "    display(export_widget)\nelse:\n",
    "    print(\"‚ö†Ô∏è Export functionality not available - pipeline not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Search Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze search quality and diversity\n",
    "def analyze_search_quality():\n",
    "    \"\"\"Analyze search result quality and diversity\"\"\"\n",
    "    if not query_pipeline:\n",
    "        print(\"‚ùå Query pipeline not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"üî¨ Search Quality Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test diverse queries\n",
    "    analysis_queries = [\n",
    "        \"news anchor speaking\",\n",
    "        \"person wearing glasses\",\n",
    "        \"studio setting\",\n",
    "        \"microphone visible\",\n",
    "        \"formal attire\",\n",
    "        \"tin t·ª©c vi·ªát nam\",\n",
    "        \"television broadcast\",\n",
    "        \"reporter interview\"\n",
    "    ]\n",
    "    \n",
    "    analysis_results = []\n",
    "    \n",
    "    for query in analysis_queries:\n",
    "        print(f\"\\nAnalyzing: '{query}'\")\n",
    "        \n",
    "        results, _ = perform_search(query, k=50)\n",
    "        \n",
    "        if results:\n",
    "            # Calculate diversity metrics\n",
    "            unique_videos = len(set(r.video_id for r in results))\n",
    "            video_diversity = unique_videos / len(results)\n",
    "            \n",
    "            # Score distribution\n",
    "            scores = [r.score for r in results]\n",
    "            score_std = np.std(scores) if len(scores) > 1 else 0\n",
    "            score_range = max(scores) - min(scores) if scores else 0\n",
    "            \n",
    "            # Video distribution\n",
    "            video_counts = {}\n",
    "            for result in results:\n",
    "                video_counts[result.video_id] = video_counts.get(result.video_id, 0) + 1\n",
    "            \n",
    "            max_frames_per_video = max(video_counts.values()) if video_counts else 0\n",
    "            avg_frames_per_video = np.mean(list(video_counts.values())) if video_counts else 0\n",
    "            \n",
    "            analysis_results.append({\n",
    "                'query': query,\n",
    "                'total_results': len(results),\n",
    "                'unique_videos': unique_videos,\n",
    "                'video_diversity': video_diversity,\n",
    "                'score_std': score_std,\n",
    "                'score_range': score_range,\n",
    "                'top_score': scores[0] if scores else 0,\n",
    "                'bottom_score': scores[-1] if scores else 0,\n",
    "                'max_frames_per_video': max_frames_per_video,\n",
    "                'avg_frames_per_video': avg_frames_per_video\n",
    "            })\n",
    "            \n",
    "            print(f\"  Results: {len(results)}, Unique videos: {unique_videos} ({video_diversity:.2%})\")\n",
    "            print(f\"  Score range: {scores[0]:.3f} - {scores[-1]:.3f} (std: {score_std:.3f})\")\n",
    "            print(f\"  Max frames per video: {max_frames_per_video}\")\n",
    "        else:\n",
    "            print(f\"  No results found\")\n",
    "    \n",
    "    if analysis_results:\n",
    "        analysis_df = pd.DataFrame(analysis_results)\n",
    "        \n",
    "        print(\"\\nüìä Quality Analysis Summary:\")\n",
    "        display(analysis_df.round(3))\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nOverall Statistics:\")\n",
    "        print(f\"  Average video diversity: {analysis_df['video_diversity'].mean():.2%}\")\n",
    "        print(f\"  Average score std: {analysis_df['score_std'].mean():.3f}\")\n",
    "        print(f\"  Average max frames per video: {analysis_df['max_frames_per_video'].mean():.1f}\")\n",
    "        \n",
    "        # Visualizations\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        # Video diversity\n",
    "        axes[0,0].bar(range(len(analysis_df)), analysis_df['video_diversity'])\n",
    "        axes[0,0].set_title('Video Diversity by Query')\n",
    "        axes[0,0].set_ylabel('Diversity (unique_videos/total_results)')\n",
    "        axes[0,0].set_xticks(range(len(analysis_df)))\n",
    "        axes[0,0].set_xticklabels(analysis_df['query'], rotation=45, ha='right')\n",
    "        \n",
    "        # Score distribution\n",
    "        axes[0,1].scatter(analysis_df['top_score'], analysis_df['score_std'])\n",
    "        axes[0,1].set_title('Score Distribution')\n",
    "        axes[0,1].set_xlabel('Top Score')\n",
    "        axes[0,1].set_ylabel('Score Standard Deviation')\n",
    "        \n",
    "        # Frames per video distribution\n",
    "        axes[1,0].bar(range(len(analysis_df)), analysis_df['max_frames_per_video'])\n",
    "        axes[1,0].set_title('Max Frames per Video')\n",
    "        axes[1,0].set_ylabel('Max Frames')\n",
    "        axes[1,0].set_xticks(range(len(analysis_df)))\n",
    "        axes[1,0].set_xticklabels(analysis_df['query'], rotation=45, ha='right')\n",
    "        \n",
    "        # Results count\n",
    "        axes[1,1].bar(range(len(analysis_df)), analysis_df['total_results'])\n",
    "        axes[1,1].set_title('Total Results per Query')\n",
    "        axes[1,1].set_ylabel('Result Count')\n",
    "        axes[1,1].set_xticks(range(len(analysis_df)))\n",
    "        axes[1,1].set_xticklabels(analysis_df['query'], rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return analysis_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Analysis button\n",
    "if query_pipeline:\n",
    "    analysis_button = widgets.Button(\n",
    "        description=\"Analyze Search Quality\",\n",
    "        button_style='success',\n",
    "        tooltip='Analyze search result quality and diversity'\n",
    "    )\n",
    "    \n",
    "    def on_analysis_clicked(b):\n",
    "        with analysis_output:\n",
    "            clear_output()\n",
    "            analyze_search_quality()\n",
    "    \n",
    "    analysis_button.on_click(on_analysis_clicked)\n",
    "    analysis_output = widgets.Output()\n",
    "    \n",
    "    display(analysis_button)\n",
    "    display(analysis_output)\nelse:\n",
    "    print(\"‚ö†Ô∏è Quality analysis not available - pipeline not initialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ SEARCH & EVALUATION READY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Use 04_training_and_reranking.ipynb to improve search results\")\n",
    "print(\"2. Use 05_end_to_end_pipeline.ipynb for complete workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Usage Guide\n",
    "\n",
    "This notebook provides comprehensive search and evaluation capabilities:\n",
    "\n",
    "### Available Search Modes:\n",
    "- **Vector Search**: Pure similarity search using CLIP embeddings\n",
    "- **Hybrid Search**: Combines multiple search strategies (recommended)\n",
    "- **Text Search**: Text-based matching (if available)\n",
    "\n",
    "### Interactive Features:\n",
    "- üéõÔ∏è **Interactive Search**: Real-time query interface with parameter controls\n",
    "- üéØ **Example Queries**: Predefined queries for different content types\n",
    "- ‚ö° **Performance Benchmark**: Speed and efficiency analysis\n",
    "- üíæ **Export Results**: Save search results in multiple formats\n",
    "- üî¨ **Quality Analysis**: Analyze result diversity and score distributions\n",
    "\n",
    "### Tips for Better Results:\n",
    "1. Use specific, descriptive queries\n",
    "2. Try both English and Vietnamese queries if applicable\n",
    "3. Use hybrid search mode for best results\n",
    "4. Experiment with query expansion for broader results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}